"""
LLM è¯„æµ‹æµæ°´çº¿ - Streamlit åº”ç”¨
äº”é˜¶æ®µæµç¨‹ï¼šé…ç½® â†’ ç”Ÿæˆå›ç­” â†’ æç¤ºè¯ç¡®è®¤ â†’ è¯„æµ‹ä¸­ â†’ ç»“æœå±•ç¤º
"""

import io
import os
import time
import re
import json
from typing import Any, Dict, Optional

import pandas as pd
import streamlit as st
import plotly.express as px

# é¡¹ç›®æ¨¡å—ï¼ˆéœ€åœ¨è¿è¡Œæ—¶å¯ç”¨ï¼‰
import config
from utils import LLMClient
from generate_evaluator_prompt import PROMPT_GENERATOR_SYSTEM_PROMPT
from batch_evaluator import extract_json_from_text, extract_evaluation


def generate_evaluator_prompt_in_app(scenario: str, north_star_metric: str, api_key: str) -> str:
    """åœ¨åº”ç”¨å†…ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆï¼ˆä¸è°ƒç”¨ sys.exitï¼Œä¾¿äº Streamlit å±•ç¤ºé”™è¯¯ï¼‰ã€‚"""
    user_prompt = f"""åœºæ™¯ï¼š{scenario}
åŒ—ææ˜ŸæŒ‡æ ‡ï¼š{north_star_metric}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°å‘˜ Promptã€‚"""
    prev = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        llm_client = LLMClient(provider="deepseek", model=st.session_state.get("model", DEFAULT_MODEL))
        return llm_client.generate(system_prompt=PROMPT_GENERATOR_SYSTEM_PROMPT, user_prompt=user_prompt)
    finally:
        if prev is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)

# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="LLM è¯„æµ‹æµæ°´çº¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ==================== å¸¸é‡ ====================
REQUIRED_CSV_COLUMNS = ["question"]
OPTIONAL_ANSWER_COLUMN = "expected_answer"
GENERATED_ANSWER_COLUMN = "generated_answer"
DEFAULT_MODEL = "deepseek-chat"
MODEL_OPTIONS = ["deepseek-chat", "deepseek-reasoner"]
PHASES = ["CONFIG", "GENERATING", "PROMPT_EDIT", "EVALUATING", "RESULT"]
GENERATOR_SYSTEM_TEMPLATE = """ä½ æ˜¯ã€Œ{scenario}ã€åœºæ™¯ä¸‹çš„ä¸“ä¸šåŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼å›´ç»•ä»¥ä¸‹åŒ—ææ˜ŸæŒ‡æ ‡æ¥å›ç­”ï¼š{north_star}ã€‚

è¦æ±‚ï¼šç›´æ¥ç»™å‡ºä¸“ä¸šã€å®Œæ•´çš„å›ç­”ï¼Œä¸è¦é¢å¤–å…ƒè¯´æ˜æˆ–é‡å¤é¢˜ç›®ã€‚"""


def init_session_state():
    """åˆå§‹åŒ– session_state"""
    if "phase" not in st.session_state:
        st.session_state.phase = "CONFIG"
    if "api_key" not in st.session_state:
        st.session_state.api_key = ""
    if "model" not in st.session_state:
        st.session_state.model = DEFAULT_MODEL
    if "scenario" not in st.session_state:
        st.session_state.scenario = ""
    if "north_star" not in st.session_state:
        st.session_state.north_star = ""
    if "uploaded_df" not in st.session_state:
        st.session_state.uploaded_df = None
    if "generated_prompt" not in st.session_state:
        st.session_state.generated_prompt = ""
    if "evaluation_prompt" not in st.session_state:
        st.session_state.evaluation_prompt = ""
    if "results_df" not in st.session_state:
        st.session_state.results_df = None
    if "eval_elapsed" not in st.session_state:
        st.session_state.eval_elapsed = None


def get_csv_template_bytes() -> bytes:
    """ç”Ÿæˆç¤ºä¾‹ CSV æ¨¡æ¿ï¼ˆä»… questionï¼Œç”¨äºã€Œç”Ÿæˆå›ç­”ã€æµç¨‹ï¼‰"""
    template_df = pd.DataFrame({
        "question": [
            "ç¤ºä¾‹é—®é¢˜ 1ï¼šè¯·ç®€è¿°åˆè§„è¦ç‚¹",
            "ç¤ºä¾‹é—®é¢˜ 2ï¼šè¯¥åœºæ™¯ä¸‹åº”å¦‚ä½•å›å¤å®¢æˆ·ï¼Ÿ",
        ],
    })
    buf = io.BytesIO()
    template_df.to_csv(buf, index=False, encoding="utf-8-sig")
    return buf.getvalue()


def validate_csv(df: pd.DataFrame) -> tuple[bool, str]:
    """éªŒè¯ CSV æ˜¯å¦åŒ…å«å¿…éœ€åˆ—ã€‚è¿”å› (æ˜¯å¦é€šè¿‡, é”™è¯¯ä¿¡æ¯)ã€‚"""
    missing = [c for c in REQUIRED_CSV_COLUMNS if c not in df.columns]
    if missing:
        return False, f"CSV ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing)}ã€‚éœ€è¦: {', '.join(REQUIRED_CSV_COLUMNS)}"
    if df.empty:
        return False, "CSV ä¸ºç©ºï¼Œè¯·ä¸Šä¼ è‡³å°‘åŒ…å«ä¸€è¡Œçš„æ•°æ®ã€‚"
    return True, ""


def run_single_generation(
    question: str,
    scenario: str,
    north_star: str,
    api_key: str,
    model: str,
) -> tuple[Optional[str], Optional[str]]:
    """æ ¹æ®ä¸šåŠ¡æè¿°ä¸åŒ—ææ˜ŸæŒ‡æ ‡å¯¹å•æ¡é¢˜ç›®ç”Ÿæˆå›ç­”ã€‚è¿”å› (å›ç­”æ–‡æœ¬, é”™è¯¯ä¿¡æ¯)ã€‚"""
    if not (question or "").strip():
        return None, "é¢˜ç›®ä¸ºç©º"
    prev = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        client = LLMClient(
            provider="deepseek",
            model=model,
            temperature=getattr(config, "DEEPSEEK_TEMPERATURE", 0.7),
            max_tokens=getattr(config, "DEEPSEEK_MAX_TOKENS", 4000),
        )
        system_prompt = GENERATOR_SYSTEM_TEMPLATE.format(scenario=scenario, north_star=north_star)
        answer = client.generate(system_prompt=system_prompt, user_prompt=(question or "").strip())
        return (answer or "").strip(), None
    except Exception as e:
        return None, str(e)
    finally:
        if prev is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)


def _fill_evaluation_prompt(prompt: str, original_text: str, model_output: str) -> str:
    """ä»…æ›¿æ¢ {original_text} ä¸ {model_output}ï¼Œé¿å… JSON ç­‰èŠ±æ‹¬å·è¢« format è¯¯è§£æã€‚"""
    return prompt.replace("{original_text}", original_text).replace("{model_output}", model_output)


def run_single_evaluation(
    row: pd.Series,
    evaluation_prompt: str,
    api_key: str,
    model: str,
) -> tuple[Optional[Dict[str, Any]], Optional[str]]:
    """å¯¹å•è¡Œæ‰§è¡Œè¯„æµ‹ã€‚model_output ä¼˜å…ˆç”¨ generated_answerï¼Œå¦åˆ™ expected_answerã€‚"""
    original_text = str(row.get("question", ""))
    model_output = str(
        row.get(GENERATED_ANSWER_COLUMN) or row.get(OPTIONAL_ANSWER_COLUMN) or ""
    ).strip()
    if not original_text.strip():
        return None, "é—®é¢˜ä¸ºç©ºï¼Œå·²è·³è¿‡"
    if not model_output or model_output.lower() in ("nan", ""):
        return None, "è¯¥è¡Œæ— å›ç­”å†…å®¹ï¼ˆéœ€å…ˆã€Œç”Ÿæˆå›ç­”ã€æˆ–ä¸Šä¼ å¸¦ expected_answer çš„ CSVï¼‰ï¼Œå·²è·³è¿‡"

    prompt_filled = _fill_evaluation_prompt(evaluation_prompt, original_text, model_output)
    prev_key = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        client = LLMClient(
            provider="deepseek",
            model=model,
            temperature=getattr(config, "DEEPSEEK_REASONER_TEMPERATURE", 0.0),
            max_tokens=getattr(config, "DEEPSEEK_REASONER_MAX_TOKENS", 2000),
            top_p=getattr(config, "DEEPSEEK_REASONER_TOP_P", None),
        )
        response = client.generate(system_prompt="", user_prompt=prompt_filled)
    except Exception as e:
        return None, str(e)
    finally:
        if prev_key is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev_key
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)

    json_obj = extract_json_from_text(response)
    if json_obj is None:
        return None, f"æ— æ³•ä»å“åº”ä¸­æå– JSON: {response[:200]}â€¦"

    try:
        evaluation_result = extract_evaluation(json_obj)
        return evaluation_result, None
    except Exception as e:
        return None, str(e)


# ==================== ä¾§è¾¹æ  ====================
def render_sidebar():
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        st.divider()

        api_key = st.text_input(
            "API Key",
            value=st.session_state.get("api_key", ""),
            type="password",
            placeholder="sk-â€¦",
            help="DeepSeek API Key",
        )
        st.session_state.api_key = api_key

        model = st.selectbox(
            "Model",
            options=MODEL_OPTIONS,
            index=MODEL_OPTIONS.index(st.session_state.get("model", DEFAULT_MODEL)),
            help="è¯„æµ‹ä½¿ç”¨çš„æ¨¡å‹",
        )
        st.session_state.model = model

        st.divider()
        st.caption("æ•°æ®æ¨¡æ¿")
        template_bytes = get_csv_template_bytes()
        st.download_button(
            label="ä¸‹è½½ CSV æ¨¡æ¿",
            data=template_bytes,
            file_name="eval_template.csv",
            mime="text/csv",
        )
        st.divider()

        if st.button("ğŸ”„ é‡æ–°å¼€å§‹", use_container_width=True):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            init_session_state()
            st.rerun()


# ==================== Phase 1: é…ç½®ä¸ä¸Šä¼  ====================
def render_phase_config():
    st.subheader("é˜¶æ®µä¸€ï¼šåœºæ™¯å®šä¹‰ä¸ä¸Šä¼ ")
    st.divider()

    c1, c2 = st.columns(2)
    with c1:
        scenario = st.text_input(
            "æµ‹è¯•åœºæ™¯",
            value=st.session_state.scenario,
            placeholder="ä¾‹å¦‚ï¼šé‡‘èåˆè§„åŠ©æ‰‹",
        )
        st.session_state.scenario = scenario
    with c2:
        north_star = st.text_input(
            "åŒ—ææ˜ŸæŒ‡æ ‡",
            value=st.session_state.north_star,
            placeholder="ä¾‹å¦‚ï¼šä¸“ä¸šåº¦ã€å®‰å…¨æ€§",
        )
        st.session_state.north_star = north_star

    st.divider()
    uploaded = st.file_uploader("ä¸Šä¼ è¯„æµ‹æ•°æ®ï¼ˆä»…é™ CSVï¼‰", type=["csv"], help="éœ€åŒ…å« question åˆ—ï¼›å¯é€‰ expected_answerï¼ˆæœ‰åˆ™å¯ä¸ç”Ÿæˆç›´æ¥è¯„æµ‹ï¼‰")

    if uploaded is not None:
        df = None
        last_err = None
        for enc in ("utf-8", "utf-8-sig", "gbk", "gb2312", "latin-1"):
            try:
                uploaded.seek(0)
                df = pd.read_csv(uploaded, encoding=enc)
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                last_err = e
                break
        if df is None:
            st.error(f"æ–‡ä»¶è§£æå¤±è´¥ï¼š{last_err or 'æ— æ³•è¯†åˆ«çš„ç¼–ç '}. è¯·ä½¿ç”¨ UTF-8 æˆ– GBK ç¼–ç çš„ CSVã€‚")
            return
        ok, err = validate_csv(df)
        if not ok:
            st.error(err)
            return
        st.session_state.uploaded_df = df
        st.caption("é¢„è§ˆï¼ˆå‰ 3 è¡Œï¼‰")
        st.dataframe(df.head(3), use_container_width=True, hide_index=True)

    st.divider()
    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("ç”Ÿæˆå›ç­”", type="primary", use_container_width=True):
            if not st.session_state.api_key.strip():
                st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ API Keyã€‚")
            elif not st.session_state.scenario.strip() or not st.session_state.north_star.strip():
                st.error("è¯·å¡«å†™æµ‹è¯•åœºæ™¯å’ŒåŒ—ææ˜ŸæŒ‡æ ‡ã€‚")
            elif st.session_state.uploaded_df is None or st.session_state.uploaded_df.empty:
                st.error("è¯·å…ˆä¸Šä¼ åŒ…å« question çš„ CSV æ–‡ä»¶ã€‚")
            else:
                st.session_state.phase = "GENERATING"
                st.rerun()
    with col_btn2:
        has_answer = (
            st.session_state.uploaded_df is not None
            and not st.session_state.uploaded_df.empty
            and (
                OPTIONAL_ANSWER_COLUMN in st.session_state.uploaded_df.columns
                or GENERATED_ANSWER_COLUMN in st.session_state.uploaded_df.columns
            )
        )
        if st.button("å·²æœ‰å›ç­”ï¼Œç›´æ¥ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆ", use_container_width=True, disabled=not has_answer):
            if not st.session_state.api_key.strip():
                st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ API Keyã€‚")
            elif not st.session_state.scenario.strip() or not st.session_state.north_star.strip():
                st.error("è¯·å¡«å†™æµ‹è¯•åœºæ™¯å’ŒåŒ—ææ˜ŸæŒ‡æ ‡ã€‚")
            else:
                with st.spinner("æ­£åœ¨ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆâ€¦"):
                    try:
                        prompt = generate_evaluator_prompt_in_app(
                            st.session_state.scenario,
                            st.session_state.north_star,
                            st.session_state.api_key,
                        )
                        st.session_state.generated_prompt = prompt
                        st.session_state.evaluation_prompt = prompt
                        st.session_state.phase = "PROMPT_EDIT"
                        st.success("è¯„æµ‹æ–¹æ¡ˆå·²ç”Ÿæˆï¼Œè¯·ç¡®è®¤å¹¶ç¼–è¾‘ä¸‹æ–¹æç¤ºè¯ã€‚")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆå¤±è´¥ï¼ˆè¯·æ£€æŸ¥ API Key ä¸ç½‘ç»œï¼‰ï¼š{e}")


# ==================== Phase 2: ç”Ÿæˆå›ç­” ====================
def render_phase_generating():
    st.subheader("é˜¶æ®µäºŒï¼šç”Ÿæˆå›ç­”")
    st.divider()

    df = st.session_state.uploaded_df
    n = len(df) if df is not None else 0
    api_key = st.session_state.api_key
    model = st.session_state.model
    scenario = st.session_state.scenario
    north_star = st.session_state.north_star

    if not api_key or df is None or n == 0:
        st.error("é…ç½®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œè¯·è¿”å›ä¸Šä¸€æ­¥ã€‚")
        if st.button("è¿”å›é…ç½®"):
            st.session_state.phase = "CONFIG"
            st.rerun()
        return

    if GENERATED_ANSWER_COLUMN not in df.columns:
        df[GENERATED_ANSWER_COLUMN] = None

    progress_bar = st.progress(0.0, text="å‡†å¤‡ä¸­â€¦")
    status = st.status("ç”Ÿæˆå›ç­”ä¸­â€¦", expanded=True)

    with status:
        for i, (idx, row) in enumerate(df.iterrows()):
            progress_bar.progress((i + 1) / n, text=f"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{n} æ¡â€¦")
            q = str(row.get("question", "") or "").strip()
            st.write(f"[{i+1}/{n}] {q[:60]}â€¦" if len(q) > 60 else f"[{i+1}/{n}] {q}")
            if not q:
                df.at[idx, GENERATED_ANSWER_COLUMN] = ""
                st.write("  â­ é¢˜ç›®ä¸ºç©ºï¼Œå·²è·³è¿‡")
                continue
            answer, err = run_single_generation(q, scenario, north_star, api_key, model)
            if err:
                df.at[idx, GENERATED_ANSWER_COLUMN] = ""
                st.write(f"  âŒ {err}")
            else:
                df.at[idx, GENERATED_ANSWER_COLUMN] = answer or ""
                st.write("  âœ… å·²ç”Ÿæˆ")

    progress_bar.progress(1.0, text="ç”Ÿæˆå®Œæˆ")
    status.update(label="ç”Ÿæˆå®Œæˆ", state="complete")
    st.session_state.uploaded_df = df

    st.divider()
    if st.button("ä¸‹ä¸€æ­¥ï¼šç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆ", type="primary", use_container_width=False):
        with st.spinner("æ­£åœ¨æ ¹æ®åœºæ™¯ä¸åŒ—ææ˜ŸæŒ‡æ ‡ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆâ€¦"):
            try:
                prompt = generate_evaluator_prompt_in_app(scenario, north_star, api_key)
                st.session_state.generated_prompt = prompt
                st.session_state.evaluation_prompt = prompt
                st.session_state.phase = "PROMPT_EDIT"
                st.success("è¯„æµ‹æ–¹æ¡ˆå·²ç”Ÿæˆï¼Œè¯·ç¡®è®¤å¹¶ç¼–è¾‘ä¸‹æ–¹æç¤ºè¯ã€‚")
                st.rerun()
            except Exception as e:
                st.error(f"ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆå¤±è´¥ï¼š{e}")


# ==================== Phase 3: æç¤ºè¯ç¡®è®¤ ====================
def render_phase_prompt_edit():
    st.subheader("é˜¶æ®µä¸‰ï¼šæç¤ºè¯ç¡®è®¤")
    st.divider()

    evaluation_prompt = st.text_area(
        "è¯„æµ‹ System Promptï¼ˆå¯ç¼–è¾‘ï¼‰",
        value=st.session_state.evaluation_prompt,
        height=320,
        help="å¯æ ¹æ®éœ€è¦ä¿®æ”¹ç”Ÿæˆçš„è¯„æµ‹æ ‡å‡†",
    )
    st.session_state.evaluation_prompt = evaluation_prompt

    if "{original_text}" not in evaluation_prompt or "{model_output}" not in evaluation_prompt:
        st.warning("æç¤ºè¯ä¸­å»ºè®®åŒ…å«å ä½ç¬¦ `{original_text}` ä¸ `{model_output}`ï¼Œä»¥ä¾¿å¯¹æ¯æ¡é¢˜ç›®è¿›è¡Œè¯„æµ‹ã€‚")

    st.divider()
    if st.button("ç¡®è®¤å¹¶å¼€å§‹è¯„æµ‹", type="primary", use_container_width=False):
        if not st.session_state.evaluation_prompt.strip():
            st.error("è¯·å¡«å†™æˆ–ä¿ç•™è¯„æµ‹æç¤ºè¯ã€‚")
            return
        st.session_state.phase = "EVALUATING"
        st.rerun()


# ==================== Phase 4: æ‰§è¡Œè¯„æµ‹ ====================
def render_phase_evaluating():
    st.subheader("é˜¶æ®µå››ï¼šæ‰§è¡Œè¯„æµ‹")
    st.divider()

    df = st.session_state.uploaded_df
    n = len(df) if df is not None else 0
    api_key = st.session_state.api_key
    model = st.session_state.model
    evaluation_prompt = st.session_state.evaluation_prompt

    if not api_key:
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ å¡«å†™ API Keyã€‚")
        st.session_state.phase = "PROMPT_EDIT"
        return
    if df is None or n == 0:
        st.error("æ— æœ‰æ•ˆæ•°æ®ï¼Œè¯·è¿”å›ä¸Šä¼  CSVã€‚")
        st.session_state.phase = "CONFIG"
        return

    progress_bar = st.progress(0.0, text="å‡†å¤‡ä¸­â€¦")
    status = st.status("è¯„æµ‹è¿›è¡Œä¸­â€¦", expanded=True)

    eval_columns = [
        "eval_priority", "factuality_score", "completeness_score",
        "adherence_score", "attractiveness_score", "weighted_total_score",
        "decision", "reason", "reasoning", "pass",
    ]
    for col in eval_columns:
        if col not in df.columns:
            df[col] = None

    start_time = time.time()
    with status:
        for i, (idx, row) in enumerate(df.iterrows()):
            progress_bar.progress((i + 1) / n, text=f"æ­£åœ¨è¯„æµ‹ç¬¬ {i+1}/{n} æ¡â€¦")
            st.write(f"[{i+1}/{n}] é¢˜ç›®: {str(row.get('question', ''))[:50]}â€¦")

            result, err = run_single_evaluation(row, evaluation_prompt, api_key, model)
            if err:
                df.at[idx, "decision"] = "ERROR"
                df.at[idx, "reason"] = f"error: {err}"
                st.write(f"  âŒ {err}")
            else:
                df.at[idx, "eval_priority"] = result.get("priority")
                df.at[idx, "factuality_score"] = result.get("factuality_score")
                df.at[idx, "completeness_score"] = result.get("completeness_score")
                df.at[idx, "adherence_score"] = result.get("adherence_score")
                df.at[idx, "attractiveness_score"] = result.get("attractiveness_score")
                df.at[idx, "weighted_total_score"] = result.get("weighted_total_score")
                df.at[idx, "decision"] = result.get("decision")
                df.at[idx, "reason"] = result.get("reason")
                df.at[idx, "reasoning"] = result.get("reasoning")
                df.at[idx, "pass"] = result.get("pass")
                st.write(f"  âœ… å¾—åˆ†: {result.get('weighted_total_score', 0):.1f} | {result.get('decision', '')}")

    elapsed = time.time() - start_time
    progress_bar.progress(1.0, text="è¯„æµ‹å®Œæˆ")
    status.update(label="è¯„æµ‹å®Œæˆ", state="complete")

    st.session_state.results_df = df
    st.session_state.eval_elapsed = elapsed
    st.session_state.phase = "RESULT"
    st.success(f"å…±è¯„æµ‹ {n} æ¡ï¼Œè€—æ—¶ {elapsed:.1f} ç§’ã€‚")
    st.rerun()


# ==================== Phase 5: ç»“æœå±•ç¤º ====================
def render_phase_result():
    st.subheader("é˜¶æ®µäº”ï¼šç»“æœå±•ç¤º")
    st.divider()

    df = st.session_state.results_df
    if df is None:
        st.warning("æš‚æ— ç»“æœï¼Œè¯·å…ˆå®Œæˆè¯„æµ‹ã€‚")
        return

    valid = df[df["weighted_total_score"].notna()]
    n_valid = len(valid)
    n_total = len(df)

    st.caption("æ ¸å¿ƒæŒ‡æ ‡")
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        avg_score = valid["weighted_total_score"].mean() if n_valid else 0
        st.metric("å¹³å‡åˆ†", f"{avg_score:.1f}" if n_valid else "â€”")
    with col2:
        pass_count = valid["pass"].sum() if "pass" in valid.columns else (valid["decision"] == "PUBLISH").sum()
        pass_rate = (pass_count / n_valid * 100) if n_valid else 0
        st.metric("é€šè¿‡ç‡", f"{pass_rate:.1f}%" if n_valid else "â€”")
    with col3:
        err_count = (df["decision"] == "ERROR").sum()
        st.metric("é”™è¯¯æ¡æ•°", int(err_count))
    with col4:
        st.metric("æ€»æ¡æ•°", n_total)
    with col5:
        elapsed = st.session_state.get("eval_elapsed")
        st.metric("æ€»è€—æ—¶", f"{elapsed:.1f} ç§’" if elapsed is not None else "â€”")

    st.divider()

    if n_valid > 0 and "weighted_total_score" in df.columns:
        st.caption("å¾—åˆ†åˆ†å¸ƒ")
        score_counts = valid["weighted_total_score"].round(0).value_counts().sort_index()
        fig = px.bar(
            x=score_counts.index.astype(int),
            y=score_counts.values,
            labels={"x": "åŠ æƒæ€»åˆ†", "y": "æ¡æ•°"},
            title="åŠ æƒæ€»åˆ†åˆ†å¸ƒ",
        )
        fig.update_layout(showlegend=False, margin=dict(t=40))
        st.plotly_chart(fig, use_container_width=True)
    st.divider()

    st.caption("å®Œæ•´ç»“æœï¼ˆå«åŸé¢˜ã€å›ç­”ã€è¯„åˆ†ç†ç”±ï¼‰")
    display_cols = ["question", GENERATED_ANSWER_COLUMN, OPTIONAL_ANSWER_COLUMN, "weighted_total_score", "decision", "reasoning"]
    display_cols = [c for c in display_cols if c in df.columns]
    st.dataframe(df[display_cols] if display_cols else df, use_container_width=True, hide_index=True)

    st.divider()
    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(
        label="ä¸‹è½½å®Œæ•´ç»“æœ CSV",
        data=buf.getvalue(),
        file_name="eval_results.csv",
        mime="text/csv",
    )


# ==================== Main ====================
def main():
    init_session_state()
    render_sidebar()

    st.title("ğŸ“Š LLM è¯„æµ‹æµæ°´çº¿")
    st.caption("é…ç½® â†’ ç”Ÿæˆå›ç­” â†’ æç¤ºè¯ç¡®è®¤ â†’ è¯„æµ‹ â†’ ç»“æœå±•ç¤º")
    st.divider()

    phase = st.session_state.phase
    if phase == "CONFIG":
        render_phase_config()
    elif phase == "GENERATING":
        render_phase_generating()
    elif phase == "PROMPT_EDIT":
        render_phase_prompt_edit()
    elif phase == "EVALUATING":
        render_phase_evaluating()
    elif phase == "RESULT":
        render_phase_result()
    else:
        st.session_state.phase = "CONFIG"
        st.rerun()


if __name__ == "__main__":
    main()
