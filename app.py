"""
LLM è¯„æµ‹æµæ°´çº¿ - Streamlit åº”ç”¨
å…­é˜¶æ®µæµç¨‹ï¼šé…ç½® â†’ ä¸šåŠ¡ Prompt â†’ è¯„ä¼° Prompt â†’ ç”Ÿæˆå›ç­” â†’ è¯„æµ‹ â†’ ç»“æœå±•ç¤º
"""

import io
import os
import time
import re
import json
from typing import Any, Dict, Optional

import pandas as pd
import streamlit as st
import plotly.express as px

# é¡¹ç›®æ¨¡å—ï¼ˆéœ€åœ¨è¿è¡Œæ—¶å¯ç”¨ï¼‰
import config
from utils import LLMClient
from generate_evaluator_prompt import PROMPT_GENERATOR_SYSTEM_PROMPT
from batch_evaluator import extract_json_from_text, extract_evaluation


def generate_evaluator_prompt_in_app(scenario: str, north_star_metric: str, api_key: str) -> str:
    """åœ¨åº”ç”¨å†…ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆï¼ˆä¸è°ƒç”¨ sys.exitï¼Œä¾¿äº Streamlit å±•ç¤ºé”™è¯¯ï¼‰ã€‚"""
    user_prompt = f"""åœºæ™¯ï¼š{scenario}
åŒ—ææ˜ŸæŒ‡æ ‡ï¼š{north_star_metric}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°å‘˜ Promptã€‚"""
    prev = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        llm_client = LLMClient(provider="deepseek", model=st.session_state.get("model", DEFAULT_MODEL))
        return llm_client.generate(system_prompt=PROMPT_GENERATOR_SYSTEM_PROMPT, user_prompt=user_prompt)
    finally:
        if prev is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)


def generate_generation_prompt_in_app(scenario: str, north_star: str, api_key: str) -> str:
    """æ ¹æ®ä¸šåŠ¡åœºæ™¯ä¸åŒ—ææ˜ŸæŒ‡æ ‡ï¼Œè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„ã€Œç”Ÿæˆ Promptã€ã€‚"""
    user_prompt = f"""ä¸šåŠ¡åœºæ™¯ï¼š
{scenario}

åŒ—ææ˜ŸæŒ‡æ ‡ï¼š
{north_star}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç”Ÿæˆä¸€ä»½å¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒçš„ä¸šåŠ¡æç¤ºè¯ï¼ˆä»…è¾“å‡ºæç¤ºè¯æ­£æ–‡ï¼Œæ— éœ€é¢å¤–è¯´æ˜ï¼‰ã€‚"""
    prev = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        llm_client = LLMClient(provider="deepseek", model=st.session_state.get("model", DEFAULT_MODEL))
        return llm_client.generate(
            system_prompt=GENERATION_PROMPT_GENERATOR_SYSTEM,
            user_prompt=user_prompt,
        )
    finally:
        if prev is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)


# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="LLM è¯„æµ‹æµæ°´çº¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ==================== å¸¸é‡ ====================
REQUIRED_CSV_COLUMNS = ["question"]
OPTIONAL_ANSWER_COLUMN = "expected_answer"
GENERATED_ANSWER_COLUMN = "generated_answer"
DEFAULT_MODEL = "deepseek-chat"
MODEL_OPTIONS = ["deepseek-chat", "deepseek-reasoner"]
PHASES = ["CONFIG", "GENERATION_PROMPT_EDIT", "GENERATING", "PROMPT_EDIT", "EVALUATING", "RESULT"]

# è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆã€Œç”Ÿæˆ Promptã€æ—¶ä½¿ç”¨çš„ç³»ç»Ÿæç¤ºè¯
GENERATION_PROMPT_GENERATOR_SYSTEM = """# Role
ä½ æ˜¯ä¸€ä½ä¸–ç•Œçº§çš„æç¤ºè¯å·¥ç¨‹å¸ˆï¼Œæ“…é•¿å°†ä¸šåŠ¡éœ€æ±‚è½¬åŒ–ä¸ºæå…·æ‰§è¡ŒåŠ›çš„ LLM ç”Ÿäº§ç¯å¢ƒæç¤ºè¯ã€‚ä½ æ·±è°™æç¤ºè¯å·¥ç¨‹çš„æœ€ä½³å®è·µï¼Œèƒ½å¤Ÿé’ˆå¯¹ç‰¹å®šä¸šåŠ¡æŒ‡æ ‡è¿›è¡Œç²¾ç»†åŒ–è°ƒä¼˜ã€‚

# Task
æ ¹æ®ç”¨æˆ·æä¾›çš„ã€ä¸šåŠ¡åœºæ™¯ã€‘å’Œã€åŒ—ææ˜ŸæŒ‡æ ‡ã€‘ï¼Œä¸ºç”¨æˆ·æ’°å†™ä¸€ä¸ªé«˜è´¨é‡çš„ã€å¯ç›´æ¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨çš„"ä¸šåŠ¡æç¤ºè¯"ã€‚

# Input
1. ä¸šåŠ¡åœºæ™¯ï¼šæè¿°è¯¥ AI äº§å“çš„å…·ä½“ç”¨é€”å’Œç”¨æˆ·ç”»åƒã€‚
2. åŒ—ææ˜ŸæŒ‡æ ‡ï¼šè¡¡é‡è¯¥ AI è¡¨ç°å¥½åçš„æ ¸å¿ƒä¸šåŠ¡æ ‡å‡†ã€‚

# Output Framework (ä½ ç”Ÿæˆçš„ä¸šåŠ¡æç¤ºè¯å¿…é¡»åŒ…å«)
1. **è§’è‰²è®¾å®š (Role)**ï¼šå®šä¹‰ä¸€ä¸ªç¬¦åˆåœºæ™¯çš„ã€ä¸“ä¸šçš„ã€å…·æœ‰ç‰¹å®šäººæ ¼ç‰¹è´¨çš„ AI è§’è‰²ã€‚
2. **ä»»åŠ¡æè¿° (Task)**ï¼šæ¸…æ™°ã€æ— æ­§ä¹‰åœ°æè¿° AI éœ€è¦å®Œæˆçš„å…·ä½“å·¥ä½œã€‚
3. **çº¦æŸæ¡ä»¶ (Constraints)**ï¼š
    - æ ¹æ®ã€åŒ—ææ˜ŸæŒ‡æ ‡ã€‘åæ¨çš„ç¡¬æ€§è¦æ±‚ï¼ˆä¾‹å¦‚ï¼šä¸¥ç¦èƒ¡è¯´å…«é“ã€å›å¤é•¿åº¦é™åˆ¶ã€å¿…é¡»åŒ…å«æŸäº›å…³é”®è¯ï¼‰ã€‚
    - é’ˆå¯¹ã€ä¸šåŠ¡åœºæ™¯ã€‘çš„åˆè§„æ€§è¦æ±‚æˆ–è¯­æ°”è¦æ±‚ã€‚
4. **æ€ç»´é“¾è¦æ±‚ (Chain of Thought)**ï¼šå¼•å¯¼ AI åœ¨è¾“å‡ºç»“æœå‰è¿›è¡Œå†…éƒ¨æ¨ç†ï¼Œä»¥ç¡®ä¿é€»è¾‘ä¸¥å¯†ï¼ˆå¦‚æœåœºæ™¯å¤æ‚ï¼‰ã€‚
5. **è¾“å‡ºæ ¼å¼ (Output Format)**ï¼šå®šä¹‰å›å¤çš„ç»“æ„ï¼ˆå¦‚ Markdownã€JSON æˆ–ç‰¹å®šè¯­æ°”çš„æ–‡æœ¬ï¼‰ã€‚

# Design Principles
- **æŒ‡æ ‡å¯¹é½**ï¼šå¦‚æœåŒ—ææ˜ŸæŒ‡æ ‡æ˜¯"ä¸“ä¸šåº¦"ï¼Œæç¤ºè¯åº”ä¾§é‡å¼•ç”¨çŸ¥è¯†åº“å’Œæœ¯è¯­ï¼›å¦‚æœæ˜¯"äº²å’ŒåŠ›"ï¼Œåˆ™ä¾§é‡è¯­æ°”è¯å’Œå…±æƒ…è¡¨è¾¾ã€‚
- **æ¨¡å—åŒ–**ï¼šç»“æ„æ¸…æ™°ï¼Œç”¨æˆ·æ‹¿åˆ°åå¯ä»¥ä¸€çœ¼çœ‹æ‡‚æ¯ä¸€éƒ¨åˆ†çš„ä½œç”¨ã€‚
- **é²æ£’æ€§**ï¼šè€ƒè™‘åˆ°å¤§æ¨¡å‹çš„è¾¹ç•Œæƒ…å†µï¼Œå¢åŠ é¢„é˜²è¯¯æ“ä½œæˆ–è¶Šæƒçš„é˜²å¾¡æ€§æè¿°ã€‚

# Language
å§‹ç»ˆä½¿ç”¨ä¸­æ–‡è¾“å‡ºç”Ÿæˆçš„ä¸šåŠ¡æç¤ºè¯ã€‚"""


def init_session_state():
    """åˆå§‹åŒ– session_state"""
    if "phase" not in st.session_state:
        st.session_state.phase = "CONFIG"
    if "api_key" not in st.session_state:
        st.session_state.api_key = ""
    if "model" not in st.session_state:
        st.session_state.model = DEFAULT_MODEL
    if "scenario" not in st.session_state:
        st.session_state.scenario = ""
    if "north_star" not in st.session_state:
        st.session_state.north_star = ""
    if "uploaded_df" not in st.session_state:
        st.session_state.uploaded_df = None
    if "generation_prompt" not in st.session_state:
        st.session_state.generation_prompt = ""
    if "generated_prompt" not in st.session_state:
        st.session_state.generated_prompt = ""
    if "evaluation_prompt" not in st.session_state:
        st.session_state.evaluation_prompt = ""
    if "results_df" not in st.session_state:
        st.session_state.results_df = None
    if "eval_elapsed" not in st.session_state:
        st.session_state.eval_elapsed = None


def get_csv_template_bytes() -> bytes:
    """ç”Ÿæˆç¤ºä¾‹ CSV æ¨¡æ¿ï¼ˆä»… questionï¼Œç”¨äºã€Œç”Ÿæˆå›ç­”ã€æµç¨‹ï¼‰"""
    template_df = pd.DataFrame({
        "question": [
            "ç¤ºä¾‹é—®é¢˜ 1ï¼šè¯·ç®€è¿°åˆè§„è¦ç‚¹",
            "ç¤ºä¾‹é—®é¢˜ 2ï¼šè¯¥åœºæ™¯ä¸‹åº”å¦‚ä½•å›å¤å®¢æˆ·ï¼Ÿ",
        ],
    })
    buf = io.BytesIO()
    template_df.to_csv(buf, index=False, encoding="utf-8-sig")
    return buf.getvalue()


def validate_csv(df: pd.DataFrame) -> tuple[bool, str]:
    """éªŒè¯ CSV æ˜¯å¦åŒ…å«å¿…éœ€åˆ—ã€‚è¿”å› (æ˜¯å¦é€šè¿‡, é”™è¯¯ä¿¡æ¯)ã€‚"""
    missing = [c for c in REQUIRED_CSV_COLUMNS if c not in df.columns]
    if missing:
        return False, f"CSV ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing)}ã€‚éœ€è¦: {', '.join(REQUIRED_CSV_COLUMNS)}"
    if df.empty:
        return False, "CSV ä¸ºç©ºï¼Œè¯·ä¸Šä¼ è‡³å°‘åŒ…å«ä¸€è¡Œçš„æ•°æ®ã€‚"
    return True, ""


def run_single_generation(
    question: str,
    system_prompt: str,
    api_key: str,
    model: str,
) -> tuple[Optional[str], Optional[str]]:
    """ä½¿ç”¨ç»™å®šçš„ç”Ÿæˆ Prompt å¯¹å•æ¡é¢˜ç›®ç”Ÿæˆå›ç­”ã€‚è¿”å› (å›ç­”æ–‡æœ¬, é”™è¯¯ä¿¡æ¯)ã€‚"""
    if not (question or "").strip():
        return None, "é¢˜ç›®ä¸ºç©º"
    if not (system_prompt or "").strip():
        return None, "ç”Ÿæˆ Prompt ä¸ºç©º"
    prev = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        client = LLMClient(
            provider="deepseek",
            model=model,
            temperature=getattr(config, "DEEPSEEK_TEMPERATURE", 0.7),
            max_tokens=getattr(config, "DEEPSEEK_MAX_TOKENS", 4000),
        )
        answer = client.generate(system_prompt=system_prompt.strip(), user_prompt=(question or "").strip())
        return (answer or "").strip(), None
    except Exception as e:
        return None, str(e)
    finally:
        if prev is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)


def _fill_evaluation_prompt(prompt: str, original_text: str, model_output: str) -> str:
    """ä»…æ›¿æ¢ {original_text} ä¸ {model_output}ï¼Œé¿å… JSON ç­‰èŠ±æ‹¬å·è¢« format è¯¯è§£æã€‚"""
    return prompt.replace("{original_text}", original_text).replace("{model_output}", model_output)


def run_single_evaluation(
    row: pd.Series,
    evaluation_prompt: str,
    api_key: str,
    model: str,
) -> tuple[Optional[Dict[str, Any]], Optional[str]]:
    """å¯¹å•è¡Œæ‰§è¡Œè¯„æµ‹ã€‚model_output ä¼˜å…ˆç”¨ generated_answerï¼Œå¦åˆ™ expected_answerã€‚"""
    original_text = str(row.get("question", ""))
    model_output = str(
        row.get(GENERATED_ANSWER_COLUMN) or row.get(OPTIONAL_ANSWER_COLUMN) or ""
    ).strip()
    if not original_text.strip():
        return None, "é—®é¢˜ä¸ºç©ºï¼Œå·²è·³è¿‡"
    if not model_output or model_output.lower() in ("nan", ""):
        return None, "è¯¥è¡Œæ— å›ç­”å†…å®¹ï¼ˆéœ€å…ˆã€Œç”Ÿæˆå›ç­”ã€æˆ–ä¸Šä¼ å¸¦ expected_answer çš„ CSVï¼‰ï¼Œå·²è·³è¿‡"

    prompt_filled = _fill_evaluation_prompt(evaluation_prompt, original_text, model_output)
    prev_key = os.environ.get("DEEPSEEK_API_KEY")
    try:
        os.environ["DEEPSEEK_API_KEY"] = api_key
        client = LLMClient(
            provider="deepseek",
            model=model,
            temperature=getattr(config, "DEEPSEEK_REASONER_TEMPERATURE", 0.0),
            max_tokens=getattr(config, "DEEPSEEK_REASONER_MAX_TOKENS", 2000),
            top_p=getattr(config, "DEEPSEEK_REASONER_TOP_P", None),
        )
        response = client.generate(system_prompt="", user_prompt=prompt_filled)
    except Exception as e:
        return None, str(e)
    finally:
        if prev_key is not None:
            os.environ["DEEPSEEK_API_KEY"] = prev_key
        else:
            os.environ.pop("DEEPSEEK_API_KEY", None)

    json_obj = extract_json_from_text(response)
    if json_obj is None:
        return None, f"æ— æ³•ä»å“åº”ä¸­æå– JSON: {response[:200]}â€¦"

    try:
        evaluation_result = extract_evaluation(json_obj)
        return evaluation_result, None
    except Exception as e:
        return None, str(e)


# ==================== ä¾§è¾¹æ  ====================
def render_sidebar():
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        st.divider()

        api_key = st.text_input(
            "API Key",
            value=st.session_state.get("api_key", ""),
            type="password",
            placeholder="sk-â€¦",
            help="DeepSeek API Key",
        )
        st.session_state.api_key = api_key

        model = st.selectbox(
            "Model",
            options=MODEL_OPTIONS,
            index=MODEL_OPTIONS.index(st.session_state.get("model", DEFAULT_MODEL)),
            help="è¯„æµ‹ä½¿ç”¨çš„æ¨¡å‹",
        )
        st.session_state.model = model

        st.divider()
        st.caption("æ•°æ®æ¨¡æ¿")
        template_bytes = get_csv_template_bytes()
        st.download_button(
            label="ä¸‹è½½ CSV æ¨¡æ¿",
            data=template_bytes,
            file_name="eval_template.csv",
            mime="text/csv",
        )
        st.divider()

        if st.button("ğŸ”„ é‡æ–°å¼€å§‹", width="stretch"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            init_session_state()
            st.rerun()


# ==================== Phase 1: é…ç½®ä¸ä¸Šä¼  ====================
def render_phase_config():
    st.subheader("é˜¶æ®µä¸€ï¼šåœºæ™¯å®šä¹‰ä¸ä¸Šä¼ ")
    st.divider()

    st.caption("ä¸šåŠ¡åœºæ™¯ï¼ˆè¯·å°½é‡è¯¦ç»†æè¿°ï¼Œè¶Šè¯¦ç»†ç”Ÿæˆçš„ Prompt è¶Šç²¾å‡†ï¼‰")
    scenario = st.text_area(
        "ä¸šåŠ¡åœºæ™¯",
        value=st.session_state.scenario,
        height=220,
        placeholder="è¯·è¯¦ç»†æè¿°ï¼š\nÂ· è¯¥ AI äº§å“çš„å…·ä½“ç”¨é€”ã€ç›®æ ‡ç”¨æˆ·ç”»åƒ\nÂ· å…¸å‹ä½¿ç”¨åœºæ™¯ä¸è¾¹ç•Œæƒ…å†µ\nÂ· å¸Œæœ›çš„è¯­æ°”ã€é£æ ¼æˆ–åˆè§„è¦æ±‚\n\nä¾‹å¦‚ï¼šé¢å‘ 6â€“10 å²å„¿ç«¥çš„æ•…äº‹ç”ŸæˆåŠ©æ‰‹ï¼Œéœ€åœ¨ 2 åˆ†é’Ÿå†…äº§å‡º 300 å­—ä»¥å†…ã€æ— æš´åŠ›æƒ…èŠ‚ã€è¯­è¨€æµ…ç™½æœ‰è¶£çš„æ•…äº‹ç‰‡æ®µâ€¦â€¦",
        help="æè¿°è¶Šè¯¦ç»†ï¼Œå¤§æ¨¡å‹ç”Ÿæˆçš„ä¸šåŠ¡æç¤ºè¯è¶Šè´´åˆä½ çš„éœ€æ±‚ã€‚",
    )
    st.session_state.scenario = scenario

    st.divider()
    north_star = st.text_input(
        "åŒ—ææ˜ŸæŒ‡æ ‡",
        value=st.session_state.north_star,
        placeholder="ä¾‹å¦‚ï¼šè¶£å‘³æ€§ã€ç¬¦åˆå„¿ç«¥å¿ƒæ™ºã€ä¸“ä¸šåº¦ã€å®‰å…¨æ€§",
        help="è¡¡é‡è¯¥ AI è¡¨ç°å¥½åçš„æ ¸å¿ƒä¸šåŠ¡æ ‡å‡†ï¼Œå¯å†™å¤šæ¡ã€‚",
    )
    st.session_state.north_star = north_star

    st.divider()
    uploaded = st.file_uploader("ä¸Šä¼ è¯„æµ‹æ•°æ®ï¼ˆä»…é™ CSVï¼‰", type=["csv"], help="éœ€åŒ…å« question åˆ—ï¼›å¯é€‰ expected_answerï¼ˆæœ‰åˆ™å¯ä¸ç”Ÿæˆç›´æ¥è¯„æµ‹ï¼‰")

    if uploaded is not None:
        df = None
        last_err = None
        for enc in ("utf-8", "utf-8-sig", "gbk", "gb2312", "latin-1"):
            try:
                uploaded.seek(0)
                df = pd.read_csv(uploaded, encoding=enc)
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                last_err = e
                break
        if df is None:
            st.error(f"æ–‡ä»¶è§£æå¤±è´¥ï¼š{last_err or 'æ— æ³•è¯†åˆ«çš„ç¼–ç '}. è¯·ä½¿ç”¨ UTF-8 æˆ– GBK ç¼–ç çš„ CSVã€‚")
            return
        ok, err = validate_csv(df)
        if not ok:
            st.error(err)
            return
        st.session_state.uploaded_df = df
        st.caption("é¢„è§ˆï¼ˆå‰ 3 è¡Œï¼‰")
        st.dataframe(df.head(3), width="stretch", hide_index=True)

    st.divider()
    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("ä¸‹ä¸€æ­¥ï¼šç”Ÿæˆ Prompt", type="primary", width="stretch"):
            if not st.session_state.api_key.strip():
                st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ API Keyã€‚")
            elif not st.session_state.scenario.strip() or not st.session_state.north_star.strip():
                st.error("è¯·å¡«å†™ä¸šåŠ¡åœºæ™¯å’ŒåŒ—ææ˜ŸæŒ‡æ ‡ã€‚")
            elif st.session_state.uploaded_df is None or st.session_state.uploaded_df.empty:
                st.error("è¯·å…ˆä¸Šä¼ åŒ…å« question çš„ CSV æ–‡ä»¶ã€‚")
            else:
                with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸šåŠ¡æç¤ºè¯â€¦"):
                    try:
                        st.session_state.generation_prompt = generate_generation_prompt_in_app(
                            st.session_state.scenario,
                            st.session_state.north_star,
                            st.session_state.api_key,
                        )
                        st.session_state.phase = "GENERATION_PROMPT_EDIT"
                        st.rerun()
                    except Exception as e:
                        st.error(f"ç”Ÿæˆ Prompt å¤±è´¥ï¼ˆè¯·æ£€æŸ¥ API Key ä¸ç½‘ç»œï¼‰ï¼š{e}")
    with col_btn2:
        has_answer = (
            st.session_state.uploaded_df is not None
            and not st.session_state.uploaded_df.empty
            and (
                OPTIONAL_ANSWER_COLUMN in st.session_state.uploaded_df.columns
                or GENERATED_ANSWER_COLUMN in st.session_state.uploaded_df.columns
            )
        )
        if st.button("å·²æœ‰å›ç­”ï¼Œç›´æ¥ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆ", width="stretch", disabled=not has_answer):
            if not st.session_state.api_key.strip():
                st.error("è¯·åœ¨ä¾§è¾¹æ å¡«å†™ API Keyã€‚")
            elif not st.session_state.scenario.strip() or not st.session_state.north_star.strip():
                st.error("è¯·å¡«å†™ä¸šåŠ¡åœºæ™¯å’ŒåŒ—ææ˜ŸæŒ‡æ ‡ã€‚")
            else:
                with st.spinner("æ­£åœ¨ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆâ€¦"):
                    try:
                        prompt = generate_evaluator_prompt_in_app(
                            st.session_state.scenario,
                            st.session_state.north_star,
                            st.session_state.api_key,
                        )
                        st.session_state.generated_prompt = prompt
                        st.session_state.evaluation_prompt = prompt
                        st.session_state.phase = "PROMPT_EDIT"
                        st.success("è¯„æµ‹æ–¹æ¡ˆå·²ç”Ÿæˆï¼Œè¯·ç¡®è®¤å¹¶ç¼–è¾‘ä¸‹æ–¹æç¤ºè¯ã€‚")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆå¤±è´¥ï¼ˆè¯·æ£€æŸ¥ API Key ä¸ç½‘ç»œï¼‰ï¼š{e}")


# ==================== Phase 2: ä¸šåŠ¡ Prompt ç¡®è®¤ï¼ˆå¯ç¼–è¾‘ï¼‰ ====================
def render_phase_generation_prompt_edit():
    st.subheader("é˜¶æ®µäºŒï¼šä¸šåŠ¡ Prompt ç¡®è®¤")
    st.divider()
    st.caption("æ ¹æ®ä¸šåŠ¡åœºæ™¯ä¸åŒ—ææ˜ŸæŒ‡æ ‡å·²ç”Ÿæˆä¸‹æ–¹ä¸šåŠ¡æç¤ºè¯ï¼Œå¯ç¼–è¾‘ã€‚ç¡®è®¤åè¿›å…¥ä¸‹ä¸€æ­¥ç”Ÿæˆã€Œè¯„ä¼° Promptã€ã€‚")

    generation_prompt = st.text_area(
        "ä¸šåŠ¡ Promptï¼ˆå¯ç¼–è¾‘ï¼‰",
        value=st.session_state.generation_prompt,
        height=280,
        help="ç”¨äºè°ƒç”¨æ¨¡å‹ç”Ÿæˆå›ç­”çš„ç³»ç»Ÿæç¤ºè¯ï¼Œæ¯æ¡é¢˜ç›®å°†ä½œä¸ºç”¨æˆ·è¾“å…¥ä¼ å…¥ã€‚",
    )
    st.session_state.generation_prompt = generation_prompt

    st.divider()
    if st.button("ä¸‹ä¸€æ­¥ï¼šç”Ÿæˆè¯„ä¼° Prompt", type="primary", width="content"):
        if not (st.session_state.generation_prompt or "").strip():
            st.error("è¯·å¡«å†™æˆ–ä¿ç•™ä¸šåŠ¡ Promptã€‚")
            return
        with st.spinner("æ­£åœ¨æ ¹æ®åœºæ™¯ä¸åŒ—ææ˜ŸæŒ‡æ ‡ç”Ÿæˆè¯„ä¼° Promptâ€¦"):
            try:
                prompt = generate_evaluator_prompt_in_app(
                    st.session_state.scenario,
                    st.session_state.north_star,
                    st.session_state.api_key,
                )
                st.session_state.generated_prompt = prompt
                st.session_state.evaluation_prompt = prompt
                st.session_state.phase = "PROMPT_EDIT"
                st.success("è¯„ä¼° Prompt å·²ç”Ÿæˆï¼Œè¯·ç¡®è®¤å¹¶ç¼–è¾‘ä¸‹æ–¹æç¤ºè¯ï¼Œå†å¼€å§‹å¤„ç†æ•°æ®ã€‚")
                st.rerun()
            except Exception as e:
                st.error(f"ç”Ÿæˆè¯„ä¼° Prompt å¤±è´¥ï¼ˆè¯·æ£€æŸ¥ API Key ä¸ç½‘ç»œï¼‰ï¼š{e}")

    if st.button("è¿”å›é…ç½®", width="content"):
        st.session_state.phase = "CONFIG"
        st.rerun()


# ==================== Phase 4: ç”Ÿæˆå›ç­” ====================
def render_phase_generating():
    st.subheader("é˜¶æ®µå››ï¼šç”Ÿæˆå›ç­”")
    st.divider()

    df = st.session_state.uploaded_df
    n = len(df) if df is not None else 0
    api_key = st.session_state.api_key
    model = st.session_state.model
    generation_prompt = st.session_state.generation_prompt

    if not api_key or df is None or n == 0 or not (generation_prompt or "").strip():
        st.error("é…ç½®æˆ–æ•°æ®ä¸å®Œæ•´ï¼Œè¯·è¿”å›ä¸Šä¸€æ­¥ã€‚")
        if st.button("è¿”å›è¯„ä¼° Prompt"):
            st.session_state.phase = "PROMPT_EDIT"
            st.rerun()
        return

    if GENERATED_ANSWER_COLUMN not in df.columns:
        df[GENERATED_ANSWER_COLUMN] = None

    # è‹¥æ‰€æœ‰æœ‰é¢˜ç›®çš„è¡Œå·²æœ‰ç”Ÿæˆå›ç­”ï¼Œåˆ™ä¸å†é‡æ–°ç”Ÿæˆï¼Œç›´æ¥å±•ç¤ºç»“æœä¸ã€Œä¸‹ä¸€æ­¥ã€ï¼ˆé¿å…ç‚¹å‡»ã€Œç”Ÿæˆè¯„æµ‹æ–¹æ¡ˆã€å rerun æ—¶åˆè·‘ä¸€éï¼‰
    rows_with_question = (df["question"].notna() & df["question"].astype(str).str.strip() != "").sum()
    if rows_with_question > 0 and GENERATED_ANSWER_COLUMN in df.columns:
        filled = (df[GENERATED_ANSWER_COLUMN].notna() & (df[GENERATED_ANSWER_COLUMN].astype(str).str.strip() != "")).sum()
        if filled >= rows_with_question:
            st.caption("ç”Ÿæˆå·²å®Œæˆï¼Œå¯ç›´æ¥ç‚¹å‡»ä¸‹æ–¹ã€Œä¸‹ä¸€æ­¥ï¼šå¼€å§‹è¯„æµ‹ã€ã€‚")
            st.session_state.uploaded_df = df
            # è·³è½¬åˆ°ä¸‹æ–¹çš„ã€Œç”Ÿæˆç»“æœ + ä¸‹ä¸€æ­¥ã€å±•ç¤ºï¼Œä¸æ‰§è¡Œä¸‹é¢çš„ for å¾ªç¯
            _render_generation_result_and_next(df, api_key)
            return

    progress_bar = st.progress(0.0, text="å‡†å¤‡ä¸­â€¦")
    status = st.status("ç”Ÿæˆå›ç­”ä¸­â€¦", expanded=True)

    with status:
        for i, (idx, row) in enumerate(df.iterrows()):
            progress_bar.progress((i + 1) / n, text=f"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{n} æ¡â€¦")
            q = str(row.get("question", "") or "").strip()
            st.write(f"[{i+1}/{n}] {q[:60]}â€¦" if len(q) > 60 else f"[{i+1}/{n}] {q}")
            if not q:
                df.at[idx, GENERATED_ANSWER_COLUMN] = ""
                st.write("  â­ é¢˜ç›®ä¸ºç©ºï¼Œå·²è·³è¿‡")
                continue
            answer, err = run_single_generation(q, generation_prompt, api_key, model)
            if err:
                df.at[idx, GENERATED_ANSWER_COLUMN] = ""
                st.write(f"  âŒ {err}")
            else:
                df.at[idx, GENERATED_ANSWER_COLUMN] = answer or ""
                st.write("  âœ… å·²ç”Ÿæˆ")

    progress_bar.progress(1.0, text="ç”Ÿæˆå®Œæˆ")
    status.update(label="ç”Ÿæˆå®Œæˆ", state="complete")
    st.session_state.uploaded_df = df

    st.divider()
    _render_generation_result_and_next(df, api_key)


def _render_generation_result_and_next(df: pd.DataFrame, api_key: str):
    """å±•ç¤ºç”Ÿæˆç»“æœï¼ˆåªè¯»ï¼‰ä¸ã€Œä¸‹ä¸€æ­¥ï¼šå¼€å§‹è¯„æµ‹ã€æŒ‰é’®ï¼ˆè¯„ä¼° Prompt å·²åœ¨å‰é¢æ­¥éª¤ç”Ÿæˆå¹¶ç¡®è®¤ï¼‰ã€‚"""
    st.subheader("ç”Ÿæˆç»“æœï¼ˆåªè¯»ï¼‰")
    st.caption("ä»¥ä¸‹ä¸ºæ ¹æ®å½“å‰ä¸šåŠ¡ Prompt å¾—åˆ°çš„å›ç­”ï¼Œä»…ä¾›æŸ¥çœ‹ä¸å¯ä¿®æ”¹ã€‚ç¡®è®¤åç‚¹å‡»ã€Œä¸‹ä¸€æ­¥ï¼šå¼€å§‹è¯„æµ‹ã€ã€‚")
    if GENERATED_ANSWER_COLUMN in df.columns:
        display_df = df[["question", GENERATED_ANSWER_COLUMN]].copy()
        display_df.columns = ["é¢˜ç›®", "ç”Ÿæˆå›ç­”"]
        st.dataframe(display_df, width="stretch", hide_index=True)
    st.divider()
    if st.button("ä¸‹ä¸€æ­¥ï¼šå¼€å§‹è¯„æµ‹", type="primary", width="content"):
        st.session_state.phase = "EVALUATING"
        st.rerun()


# ==================== Phase 3: è¯„ä¼° Prompt ç¡®è®¤ï¼ˆå¯ç¼–è¾‘ï¼‰ ====================
def render_phase_prompt_edit():
    st.subheader("é˜¶æ®µä¸‰ï¼šè¯„ä¼° Prompt ç¡®è®¤")
    st.divider()
    st.caption("ä¸Šä¸€æ­¥å·²ç”Ÿæˆè¯„ä¼°ç”¨æç¤ºè¯ï¼Œå¯ç¼–è¾‘ã€‚ç¡®è®¤åè¿›å…¥ã€Œå¤„ç†æ•°æ®ã€ï¼šå…ˆç”Ÿæˆå›ç­”ï¼Œå†æ‰§è¡Œè¯„æµ‹ã€‚")

    evaluation_prompt = st.text_area(
        "è¯„ä¼° Promptï¼ˆå¯ç¼–è¾‘ï¼‰",
        value=st.session_state.evaluation_prompt,
        height=320,
        help="å¯æ ¹æ®éœ€è¦ä¿®æ”¹ç”Ÿæˆçš„è¯„æµ‹æ ‡å‡†ï¼›é¡»åŒ…å«å ä½ç¬¦ {original_text} ä¸ {model_output}ã€‚",
    )
    st.session_state.evaluation_prompt = evaluation_prompt

    if "{original_text}" not in evaluation_prompt or "{model_output}" not in evaluation_prompt:
        st.warning("æç¤ºè¯ä¸­å»ºè®®åŒ…å«å ä½ç¬¦ `{original_text}` ä¸ `{model_output}`ï¼Œä»¥ä¾¿å¯¹æ¯æ¡é¢˜ç›®è¿›è¡Œè¯„æµ‹ã€‚")

    st.divider()
    if st.button("ç¡®è®¤å¹¶å¼€å§‹å¤„ç†æ•°æ®", type="primary", width="content"):
        if not st.session_state.evaluation_prompt.strip():
            st.error("è¯·å¡«å†™æˆ–ä¿ç•™è¯„ä¼°æç¤ºè¯ã€‚")
            return
        st.session_state.phase = "GENERATING"
        st.rerun()

    if st.button("è¿”å›ä¸šåŠ¡ Prompt", width="content"):
        st.session_state.phase = "GENERATION_PROMPT_EDIT"
        st.rerun()


# ==================== Phase 5: æ‰§è¡Œè¯„æµ‹ ====================
def render_phase_evaluating():
    st.subheader("é˜¶æ®µäº”ï¼šæ‰§è¡Œè¯„æµ‹")
    st.divider()

    df = st.session_state.uploaded_df
    n = len(df) if df is not None else 0
    api_key = st.session_state.api_key
    model = st.session_state.model
    evaluation_prompt = st.session_state.evaluation_prompt

    if not api_key:
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ å¡«å†™ API Keyã€‚")
        st.session_state.phase = "PROMPT_EDIT"
        return
    if df is None or n == 0:
        st.error("æ— æœ‰æ•ˆæ•°æ®ï¼Œè¯·è¿”å›ä¸Šä¼  CSVã€‚")
        st.session_state.phase = "CONFIG"
        return

    progress_bar = st.progress(0.0, text="å‡†å¤‡ä¸­â€¦")
    status = st.status("è¯„æµ‹è¿›è¡Œä¸­â€¦", expanded=True)

    eval_columns = [
        "eval_priority", "factuality_score", "north_star_score", "completeness_score",
        "weighted_total_score", "decision", "reason", "reasoning", "pass",
    ]
    for col in eval_columns:
        if col not in df.columns:
            df[col] = None

    start_time = time.time()
    with status:
        for i, (idx, row) in enumerate(df.iterrows()):
            progress_bar.progress((i + 1) / n, text=f"æ­£åœ¨è¯„æµ‹ç¬¬ {i+1}/{n} æ¡â€¦")
            st.write(f"[{i+1}/{n}] é¢˜ç›®: {str(row.get('question', ''))[:50]}â€¦")

            result, err = run_single_evaluation(row, evaluation_prompt, api_key, model)
            if err:
                df.at[idx, "decision"] = "ERROR"
                df.at[idx, "reason"] = f"error: {err}"
                st.write(f"  âŒ {err}")
            else:
                df.at[idx, "eval_priority"] = result.get("priority")
                df.at[idx, "factuality_score"] = result.get("factuality_score")
                df.at[idx, "north_star_score"] = result.get("north_star_score")
                df.at[idx, "completeness_score"] = result.get("completeness_score")
                df.at[idx, "weighted_total_score"] = result.get("weighted_total_score")
                df.at[idx, "decision"] = result.get("decision")
                df.at[idx, "reason"] = result.get("reason")
                df.at[idx, "reasoning"] = result.get("reasoning")
                df.at[idx, "pass"] = result.get("pass")
                st.write(f"  âœ… å¾—åˆ†: {result.get('weighted_total_score', 0):.1f} | {result.get('decision', '')}")

    elapsed = time.time() - start_time
    progress_bar.progress(1.0, text="è¯„æµ‹å®Œæˆ")
    status.update(label="è¯„æµ‹å®Œæˆ", state="complete")

    st.session_state.results_df = df
    st.session_state.eval_elapsed = elapsed
    st.session_state.phase = "RESULT"
    st.success(f"å…±è¯„æµ‹ {n} æ¡ï¼Œè€—æ—¶ {elapsed:.1f} ç§’ã€‚")
    st.rerun()


# ==================== Phase 6: ç»“æœå±•ç¤º ====================
def render_phase_result():
    st.subheader("é˜¶æ®µå…­ï¼šç»“æœå±•ç¤º")
    st.divider()

    df = st.session_state.results_df
    if df is None:
        st.warning("æš‚æ— ç»“æœï¼Œè¯·å…ˆå®Œæˆè¯„æµ‹ã€‚")
        return

    score_numeric = pd.to_numeric(df["weighted_total_score"], errors="coerce") if "weighted_total_score" in df.columns else pd.Series(dtype=float)
    valid = df[score_numeric.notna()]
    n_valid = len(valid)
    n_total = len(df)

    st.caption("æ ¸å¿ƒæŒ‡æ ‡")
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        avg_score = score_numeric.mean() if score_numeric.notna().any() else 0
        st.metric("å¹³å‡åˆ†", f"{avg_score:.1f}" if score_numeric.notna().any() else "â€”")
    with col2:
        pass_count = valid["pass"].sum() if "pass" in valid.columns else (valid["decision"] == "PUBLISH").sum()
        pass_rate = (pass_count / n_valid * 100) if n_valid else 0
        st.metric("é€šè¿‡ç‡", f"{pass_rate:.1f}%" if n_valid else "â€”")
    with col3:
        err_count = (df["decision"] == "ERROR").sum()
        st.metric("é”™è¯¯æ¡æ•°", int(err_count))
    with col4:
        st.metric("æ€»æ¡æ•°", n_total)
    with col5:
        elapsed = st.session_state.get("eval_elapsed")
        st.metric("æ€»è€—æ—¶", f"{elapsed:.1f} ç§’" if elapsed is not None else "â€”")

    st.divider()

    if n_valid > 0 and "weighted_total_score" in df.columns:
        st.caption("å¾—åˆ†åˆ†å¸ƒ")
        score_series = pd.to_numeric(valid["weighted_total_score"], errors="coerce").dropna()
        if len(score_series) > 0:
            score_counts = score_series.round(0).value_counts().sort_index()
            fig = px.bar(
                x=score_counts.index.astype(int),
                y=score_counts.values,
                labels={"x": "åŠ æƒæ€»åˆ†", "y": "æ¡æ•°"},
                title="åŠ æƒæ€»åˆ†åˆ†å¸ƒ",
            )
            fig.update_layout(showlegend=False, margin=dict(t=40))
            st.plotly_chart(fig, width="stretch")
        else:
            st.caption("æ— æœ‰æ•ˆæ•°å€¼å¾—åˆ†ï¼Œè·³è¿‡å¾—åˆ†åˆ†å¸ƒå›¾ã€‚")
    st.divider()

    # æœ¬æ¬¡ä½¿ç”¨çš„ Promptï¼ˆä¾›æ ¸æŸ¥ï¼‰
    st.caption("æœ¬æ¬¡ä½¿ç”¨çš„ Promptï¼ˆä¾›æ ¸æŸ¥ï¼‰")
    with st.expander("ä¸šåŠ¡ Promptï¼ˆç”Ÿæˆå›ç­”æ—¶ä½¿ç”¨ï¼‰", expanded=False):
        gen_prompt = st.session_state.get("generation_prompt") or ""
        st.text_area("ä¸šåŠ¡ Prompt", value=gen_prompt, height=200, disabled=True, label_visibility="collapsed")
    with st.expander("è¯„ä¼° Promptï¼ˆè¯„æµ‹æ—¶ä½¿ç”¨ï¼‰", expanded=False):
        eval_prompt = st.session_state.get("evaluation_prompt") or ""
        st.text_area("è¯„ä¼° Prompt", value=eval_prompt, height=280, disabled=True, label_visibility="collapsed")
    st.divider()

    # å„ç»´åº¦å°åˆ†ä¸€è§ˆï¼ˆä»…å±•ç¤ºå¸¸ç”¨ç»´åº¦ï¼Œä¸å±•ç¤ºå§‹ç»ˆä¸º 0 çš„éµå¾ªåº¦/å¸å¼•åŠ›ï¼‰
    score_col_order = ["factuality_score", "north_star_score", "completeness_score", "weighted_total_score"]
    score_label_map = {
        "factuality_score": "äº‹å®æ€§/å®‰å…¨æ€§",
        "north_star_score": "åŒ—ææ˜ŸæŒ‡æ ‡",
        "completeness_score": "å®Œæ•´æ€§ä¸è¿è´¯æ€§",
        "weighted_total_score": "åŠ æƒæ€»åˆ†",
    }
    existing_score_cols = [c for c in score_col_order if c in df.columns]
    if existing_score_cols:
        st.caption("å„ç»´åº¦å°åˆ†")
        labels = [score_label_map[c] for c in existing_score_cols]
        score_df = df[existing_score_cols].copy()
        score_df.columns = labels
        st.dataframe(score_df, width="stretch", hide_index=True, column_config={lb: st.column_config.NumberColumn(lb, format="%.1f") for lb in labels})
        st.divider()

    st.caption("å®Œæ•´ç»“æœï¼ˆå«åŸé¢˜ã€å›ç­”ã€å„ç»´åº¦å°åˆ†ã€æ€»åˆ†ã€å†³ç­–ä¸ç†ç”±ï¼‰")
    st.caption("è¯´æ˜ï¼šREJECT è¡¨ç¤ºã€Œäº‹å®æ€§/å®‰å…¨æ€§ã€åˆ†æ•°ä½äºé˜ˆå€¼ï¼ˆ0â€“10 åˆ†åˆ¶ä½äº 5 åˆ†ï¼Œæˆ– 0â€“100 åˆ†åˆ¶ä½äº 50 åˆ†ï¼‰ï¼Œä¸æ€»åˆ†æ— å…³ã€‚")
    display_cols = [
        "question", GENERATED_ANSWER_COLUMN, OPTIONAL_ANSWER_COLUMN,
        "factuality_score", "north_star_score", "completeness_score",
        "weighted_total_score", "decision", "reason", "reasoning",
    ]
    display_cols = [c for c in display_cols if c in df.columns]
    col_config = {}
    for col, label in [
        ("factuality_score", "äº‹å®æ€§/å®‰å…¨æ€§"),
        ("north_star_score", "åŒ—ææ˜ŸæŒ‡æ ‡"),
        ("completeness_score", "å®Œæ•´æ€§ä¸è¿è´¯æ€§"),
        ("weighted_total_score", "åŠ æƒæ€»åˆ†"),
    ]:
        if col in display_cols:
            col_config[col] = st.column_config.NumberColumn(label, format="%.1f")
    st.dataframe(
        df[display_cols] if display_cols else df,
        width="stretch",
        hide_index=True,
        column_config=col_config if col_config else None,
    )

    st.divider()
    buf = io.BytesIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    st.download_button(
        label="ä¸‹è½½å®Œæ•´ç»“æœ CSV",
        data=buf.getvalue(),
        file_name="eval_results.csv",
        mime="text/csv",
    )


# ==================== Main ====================
def main():
    init_session_state()
    render_sidebar()

    st.title("ğŸ“Š LLM è¯„æµ‹æµæ°´çº¿")
    st.caption("é…ç½® â†’ ä¸šåŠ¡ Prompt â†’ è¯„ä¼° Prompt â†’ ç”Ÿæˆå›ç­” â†’ è¯„æµ‹ â†’ ç»“æœå±•ç¤º")
    st.divider()

    phase = st.session_state.phase
    if phase == "CONFIG":
        render_phase_config()
    elif phase == "GENERATION_PROMPT_EDIT":
        render_phase_generation_prompt_edit()
    elif phase == "GENERATING":
        render_phase_generating()
    elif phase == "PROMPT_EDIT":
        render_phase_prompt_edit()
    elif phase == "EVALUATING":
        render_phase_evaluating()
    elif phase == "RESULT":
        render_phase_result()
    else:
        st.session_state.phase = "CONFIG"
        st.rerun()


if __name__ == "__main__":
    main()
